{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOnheBOSJ2Qxc9A8q4G8AP9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Intorduction to Convolutional Neural Network (CNN):"],"metadata":{"id":"Mx-7qCXkcw7V"}},{"cell_type":"markdown","source":["A **Convolutional Neural Network (CNN)** is a Deep Learning algorithm that can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image, and be able to differentiate one from the other."],"metadata":{"id":"PoIUcqmZcyub"}},{"cell_type":"markdown","source":["In a regular Neural Network there are three types of layers:\n","* **Input Layer**: It’s the layer in which we give input to our model. The number of neurons in this layer is equal to the total number of features in our data.\n","* **Hidden Layer**: he input from the Input layer is then fed into the hidden layer. There can be many hidden layers depending on our model and data size.\n","* **Output Layer**: The output from the hidden layer is then fed into a logistic function like sigmoid or softmax which converts the output of each class into the probability score of each class."],"metadata":{"id":"DaWCFLeBczLU"}},{"cell_type":"markdown","source":["#### CNN Architecture:"],"metadata":{"id":"MGbwcemydJMM"}},{"cell_type":"markdown","source":["**Convolutional Neural Network (CNN)** consists of multiple layers like the input layer, Convolutional layer, Pooling layer, and fully connected layers."],"metadata":{"id":"F18guspFeqnU"}},{"cell_type":"markdown","source":["#### Overall Process:"],"metadata":{"id":"sW1CvRide_My"}},{"cell_type":"markdown","source":["* **Input Layer**: We have a image a 2D Matrix as an input.\n","\n","* **Convolutional Layer**: On that we apply filters by sliding (Striding) 2D Matrix -> 2D Matrix (Lesser Dimension). Often called as the feature map. <br>\n","Note: If there are 'k' filters applied, then k feature maps are produced.\n","\n","* **Pooling**: We apply subsampling, to get a more compact feature map. <br>\n","The convolutional expands the input space, pooling reduces the same. Combination of these two can be applied few times. Also introduces invariance.\n","\n","* **Output Layer**: The output from the fully connected layers is then fed into a logistic function for classification tasks like sigmoid or softmax which converts the output of each class into the probability score of each class."],"metadata":{"id":"ea7d4_oLe_AL"}},{"cell_type":"markdown","source":["## Image Filters & Effects:"],"metadata":{"id":"v9Nrv-B5hdDc"}},{"cell_type":"markdown","source":["We will going to use pilgram, a library, which allows us to apply filters and effects onto images in python."],"metadata":{"id":"lDU9HMk8m71r"}},{"cell_type":"code","source":["!pip install pilgram\n","import PIL.Image\n","import pilgram"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyc2CkffhZww","executionInfo":{"status":"ok","timestamp":1723314647862,"user_tz":-300,"elapsed":4546,"user":{"displayName":"Muhammad Rauhan","userId":"16281905744292097634"}},"outputId":"f4544e65-5da0-4535-caad-d99936d04633"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pilgram\n","  Downloading pilgram-1.2.1-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pilgram) (1.26.4)\n","Downloading pilgram-1.2.1-py3-none-any.whl (817 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/817.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/817.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.4/817.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pilgram\n","Successfully installed pilgram-1.2.1\n"]}]},{"cell_type":"markdown","source":["### Filters:"],"metadata":{"id":"DNZTtKXsnjV9"}},{"cell_type":"code","source":["img = PIL.Image.open('birds.jpg')"],"metadata":{"id":"f2bGtBDUjZ6q","executionInfo":{"status":"ok","timestamp":1723315242222,"user_tz":-300,"elapsed":416,"user":{"displayName":"Muhammad Rauhan","userId":"16281905744292097634"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["pilgram.lofi(img).save('filtered.jpg')\n","pilgram.kelvin(img).save('filtered2.jpg')\n","pilgram.inkwell(img).save('filtered3.jpg')"],"metadata":{"id":"DzbuU856l8u1","executionInfo":{"status":"ok","timestamp":1723315758114,"user_tz":-300,"elapsed":425,"user":{"displayName":"Muhammad Rauhan","userId":"16281905744292097634"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Custom Filters:"],"metadata":{"id":"swBtJMO_oDzD"}},{"cell_type":"code","source":["img2 = PIL.Image.open('animal.jpg')\n","\n","pilgram.css.saturate(img2, 2).save('filtered4.jpg')\n","pilgram.css.brightness(img2, 0.5).save('filtered5.jpg')"],"metadata":{"id":"CIqq38cioa0V","executionInfo":{"status":"ok","timestamp":1723316089902,"user_tz":-300,"elapsed":393,"user":{"displayName":"Muhammad Rauhan","userId":"16281905744292097634"}}},"execution_count":8,"outputs":[]}]}