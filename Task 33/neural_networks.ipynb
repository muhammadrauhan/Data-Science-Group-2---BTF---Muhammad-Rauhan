{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 33: Neural Networks Basics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks:\n",
    "<br>\n",
    "A neural network is a connected network (where nodes are interconnected and there are several layers) which takes an input value and compute the desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components of a Neural Network:\n",
    "A typical neural network comprises of the following components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input Layer.\n",
    "- Hidden Layer (where the computations and calculations will be happening).\n",
    "- Output Layer.\n",
    "- Weights & Bias (associated with the input values.\n",
    "- Activation Function.\n",
    "- Loss Function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Layers:*** Layers are used to hold the neurons and pass it on to the subsequent layers. Each neuron is a mathematical operation that takes its input multiplies it by the weight associated with it and then passes the sum through the activation functions to the other neurons. Types of layers are\n",
    "- Input layer\n",
    "- Hidden layer\n",
    "- Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Weights and Bias:*** Weights are chosen at random in the beginning and optimized during training to reduce the loss. Bias it's simply a constant value that is added to the weights sum of inputs to offset the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Activation Function:*** An activation function is basically normalizing the computed input to produce an output. There can be various activation functions like sigmoid function, linear function, softmax and relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign input values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_value = np.array([[0,0],[0,1],[1,1],[1,0]])\n",
    "inp_value.shape\n",
    "inp_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign output values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.array([0,1,1,0])\n",
    "output = output.reshape(4,1)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1],\n",
       "       [0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.array([[0.1],[0.2]])\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_func(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative of Sigmoid Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der(x):\n",
    "    return sigmoid_func(x) * (1 - sigmoid_func(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights:\n",
      " [[-0.41953547]\n",
      " [ 8.98887811]]\n",
      "\n",
      "Updated Bias: [-4.19706344]\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(10000):\n",
    "    inp_arr = inp_value\n",
    "    \n",
    "    weighted_sum = np.dot(inp_arr, weights) + bias\n",
    "    first_output = sigmoid_func(weighted_sum)\n",
    "    \n",
    "    error = first_output - output\n",
    "    total_error = np.square(np.subtract(first_output,output)).mean()\n",
    "    #print(total_error)\n",
    "    \n",
    "    first_der = error\n",
    "    second_der = der(first_output)\n",
    "    derivative = first_der * second_der\n",
    "    \n",
    "    t_input = inp_value.T # transpose the input values\n",
    "    final_derivative = np.dot(t_input,derivative)\n",
    "    \n",
    "    # update weights\n",
    "    weights = weights - 0.05 * final_derivative\n",
    "    \n",
    "    # update bias\n",
    "    for i in derivative:\n",
    "        bias = bias - 0.05 * i\n",
    "\n",
    "print(\"Updated weights:\\n\", weights)\n",
    "print(\"\\nUpdated Bias:\", bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now to get the prediction done we will check it for the new value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Result: [0.99177089]\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([0,1])\n",
    "\n",
    "result = np.dot(pred, weights) + bias\n",
    "\n",
    "res = sigmoid_func(result)\n",
    "\n",
    "print(\"Predicted Result:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for [0,1] the target output is 1. Our result is basically 0.9917 so it's pretty accurate. This is how you can implement **Neural Networks** in python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
